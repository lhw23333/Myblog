[TOC]
https://zhuanlan.zhihu.com/p/27846162
## 游戏编程概述
### 一，游戏编程的发展
硬件平台的发展，解放生产力，早期平台基本使用汇编语言，调试困难，没有开发工具和SDK（开放代码库），以及大量低质量的游戏涌入市场，导致市场崩溃，大量实体光盘被当作垃圾处理（雅达利大爆炸）。  
进入千禧年后使用高级语言开发，提高开发效率**中间件即开源的出现**（引擎，物理系统）

### 二，游戏循环
整个游戏程序的核心流程控制称为游戏循环。之所以是一个循环，是因为游戏总是不断地执行一系列动作直到玩家退出。每迭代一次游戏循环为1帧。大部分实时游戏每秒钟更新30-60帧。如果一个游戏跑60FPS（帧/秒），那么这个游戏循环每秒要执行60次。

#### 1.传统的游戏循环
一个传统的游戏循环可以分成3部分：处理输入、更新游戏世界、生成输出。一个基本的游戏循环
- input  
会检查各种输入设备，比如键盘、鼠标、手柄。任何外部的输入在这一阶段都要处理完成。网络数据的输入
- update  
会执行所有激活并且需要更新的对象。这可能会有成千上万个游戏对象。
- generate outputs 生成输出  
图形渲染的三个阶段，其他如音频，涵盖了音效、背景音乐、对话，力反馈的输出。对于多人游戏还涉及到

#### 2.多线程下的游戏循环
当我们的画质精致到一定成都时候，我们画面渲染阶段就会十分消耗时间，如果只有一个线程，渲染和更新逻辑都在一个线程时，我们的帧率就会被影响。  

为了完成以上想法，主线程必须处理所有输入、更新游戏世界、处理所有图形以外的输出。它必须提交相关数据给第二条线程，那么第二条线程就可以渲染所有图像。  

但是，当渲染线程绘制的时候，主线程该干什么？我们不想它简单地等着渲染结束，因为这样比单线程还慢。解决的办法是让渲染线程比主线程慢1帧。这个方法的缺点就是会增加输入延迟，玩家的输入要更久才能在画面上有所反馈。假设跳跃键在第2帧就按下。在多线程游戏循环下，输入直到第3帧才开始处理。图形要到第4帧结束才能看到。

### 三、时间和游戏
真实时间 和 游戏时间。比如30FPS(Frame Per Second)的游戏，每帧大约用时33ms。
#### 1.通过处理时间增量来表示游戏逻辑
如果直接使用游戏时间来表示游戏逻辑的话，30FPS和60FPS不同帧率下游戏表现不同，比如移动速度不同，所以我们引入时间增量（deltaTime），即上一帧所运行的真实时间。

    while game is running
        realDeltaTime = time since last frame
        gameDeltaTime = realDeltaTime * gameTimeFactor
    
        //进程输入
        ···
        update game world with gameDeltaTime
    
        //渲染输出
        ···
    loop
现在虽然还可以正常运行，但在物理模拟上还是会有一些问题，所以需要通过锁帧的手段来避免。  
如果出现一些复杂情况，导致某帧比目标帧率的时长长怎么办？为了跟上目标帧率，我们会直接丢弃这一帧，视觉上会有卡顿，所以我们要避免在普通机器上进行过于复杂的渲染。

### 四、游戏对象
- 普通对象 需要绘制也需要更新
- 静态对象 建筑地图等，需要绘制，但不需要更新
- 需要更新但不许需要绘制 摄像机触发器等
- 游戏循环中的对象，class GameObject，通过继承基类或者实现接口

## 图形
图形学的研究内容非常广泛，平时我们开发游戏或者VR应用用到的，属于其中的一个分支：实时渲染（RealtimeRendering）  一，渲染管线

#### 1.什么是渲染管线
渲染管线也称为渲染流水线或像素流水线或像素管线，在某种程度上可以把渲染管线比喻为工厂里面常见的各种**生产流水线**，工厂里的生产流水线是为了提高产品的生产能力和效率，而渲染管线则是**提高显卡的工作能力和效率**。

渲染管线的主要功能就是决定在给定虚拟相机、三维物体、光源、照明模式，以及纹理等诸多条件的情况下，生成或绘制一幅二维图像的过程。

#### 2.渲染管线的流程
##### 2.1总流程图
![image](https://pic3.zhimg.com/80/v2-a1665bf2063e67a0d924e10c2121600e_720w.jpg)

##### 应用阶段

构建图元，对shader进行设置 CPU先对渲染状态进行设置，当准备好后，像缓冲区加入一个命令，DC将这些命令发送给GPU，开始渲染，而一次DC CPU会进行许多工作，比如检测渲染状态。所以要减少DC次数，将模型合并在一起提交   
现在引擎会经过排序，将渲染状态相同 一样的对象连续绘制，所以drawcall并不是限制我们渲染效率的原因，而是Set Pass Call是消耗的重点，它的作用是传递并改变Render State，具体作用就是，把当前需要用到的材质信息，贴图信息，Shader Pass信息等传递到GPU，而Drawcall则是下命令让GPU绘制一堆三角形，至于绘制命令本身实际上并不昂贵。所以可以将同种shader的模型进行合并，并依次drawcall   

如果想减少DC
一般是使用GPU instance 通过指定同一套材质属性，同一套管线状态和同一个模型，在屏幕上同时绘制多次，然和这有一些限制条件，即使贴图可以打包Atlas，材质属性和模型网格可以打包StructuredBuffer，也没法避免每次绘制时顶点数必须一样这一个致命的限制。   

##### 几何阶段
![image](https://pic4.zhimg.com/80/v2-872ceab76e6c2030bed2fcce4adc6ad3_720w.jpg)

顶点着色器    
主要就是把顶点坐标从模型空间变换到齐次裁剪空间。

裁剪(culling)   
因为在我们的屏幕上，有很多模型实际上是看不见的（比如被其他模型遮挡住的）。在图形学中，我们的屏幕能看见的东西，被称作摄像机视口。摄像机所能看见的东西是一个视椎体，在这个视椎体之外的东西会被先裁剪掉，有遮挡关系的也会裁剪掉，能看见什么，我们之后处理什么。这样会大大优化性能。  
- 视椎体剔除 应用阶段
- 遮挡剔除  应用阶段
- 视口剔除  几何阶段
- 背面剔除
- 深度剔除  光栅化阶段末期的融合阶段执行，又叫深度检测(或Z缓存检测)。每次将一个图元回执为相应的像素时，都会计算像素位置处图元的深度值，和深度缓存中对应像素的值进行比较，如果新计算出的深度小于缓存中的深度，则更新深度缓存中的值；如果深度值大于深度缓冲中的值，则计算结果被舍弃，深度缓冲的值也无需更新。

屏幕映射  
屏幕空间是个二维坐标系（平面的，只有x,y），几何图元是三维的（x,y,z）。这一步就是把三维的几何图元一一映射到二维的屏幕空间上。

##### 光栅化阶段
三角形设置  
三个顶点组成一个三角形面片，而这个三角形面片到底在屏幕里占多少像素呢？这就需要知道三角形边缘的表示方式了，所谓的三角形设置，就是输出一个三角形的边的数据，给下一个阶段。  

三角形遍历  
这个阶段是，遍历每一个像素，去检查是否被一个三角网格所覆盖，如果覆盖就会生存一个片元。  这一步会得到很多片元。所谓的片元，类似于像素，但不是像素。片元是一个状态集合，它所包含的信息比像素多很多，比如深度信息法线纹理之类的，都会包含在片元里，算是像素的前身。  

片元着色器  
shader的另一个部分。shader其实一共就俩部分，顶点着色器和片元着色器。我们所谓的贴图纹理采样，就是在这一步完成的。这部分大量的信息在shader编写的范畴里。

逐片元操作  
![image](https://pic1.zhimg.com/v2-be584fc85347b7c9c01405d57dab5050_r.jpg)  
一个片元，要经过模板测试，深度测试，最终才能和上一帧的像素进行混合或者覆盖，然后进入颜色缓冲区，变成我们肉眼看到的，屏幕上的像素。一旦有一个片元没有通过测试，那就会被废弃。  通过测试可以根据Alpha进行混合，用来实现半透明的效果，半透明物体的绘制需要严格遵守画家算法由远及近进行绘制

### 减少Draw call
通常情况下如果想减少DC有以下方法：

1. 对于使用同材质的临近的Mesh执行合并操作。
2. 收集拥有相同的PipelineState的渲染对象并同时提交。
3. 多线程并行提交。
4. 换更好的硬件

- 第一个方案，毫无疑问可以进垃圾桶了，无论从CPU，还是内存，还是GPU，还是工程的可维护性，这都是个百害无一利的方案。静态合并Mesh增加包体，动态合并Mesh需要调动CopyBufferRegion指令，再加上剔除精度的下降，这些算力和带宽的消耗已经比多的那一点Drawcall高出许多了，就连Unity都宣布Batching已经进垃圾桶了，可见这个方案有多么落后。

- 第二个方案，是目前公认的最通用的方法，Unity的SRP Batcher就是类似的思路，在DirectX12中，有相同的Mesh Layout和相同的Shader Pass的渲染对象都可以使用相同的PipelineState，我们这里的方案是把Shader和MeshLayout这两个整数加起来，作为一个HashMap的Key，就可以在剔除时把相同的对象放置到一起，这会在下方详细介绍。

- 第三个方案是目前主流现代Graphics API支持且推荐的优化方法。先前有被问到过：GPU渲染不都是有严格的先后顺序的吗？为什么可以并行提交？
那么这个问题中，就出现了两处错误。首先，GPU中不同的Drawcall并不是严格先后排序的，比如先提交了A，再提交B，并在A和B之间插入了一个SetRenderTarget，这时有可能是B先往新的Render Target上绘制，而A还在同时的往旧的Render Target上绘制，互不干涉内政，这就是为何要有Resource Barrier和Fence的原因。第二，CPU的并行提交和GPU Queue的执行毫无联系，MSDN的示意图非常清晰的证明了这一点：

![](https://pic1.zhimg.com/80/v2-5c9529e083deae3837f5ccafbb55cc00_720w.jpg)

可以看到，CPU提交是经过CommandList，而GPU执行的顺序是在CommandQueue中的，CPU的提交和GPU的执行甚至都不在同一帧内，更不用说和执行顺序有何关系，至于Queue在提交时是否是纯GPU的工作，是否有后台驱动的线程或者进程介入，这个是厂家的活，我们无从得知，只需要知道ExecuteCommandQueue是一个立即返回的异步操作即可。

通过先前铺垫好的Job System，让剔除和合批工作分到不同的Job内执行，主相机与阴影的剔除合批分别处于不同Job，而Depth Pass，Geometry Pass，Shadowmap Pass，Transparent Pass也分别处于不同Job，中间通过构建依赖保证先后顺序。这样，同时段至少有2个线程，至多有4个线程是在同时执行提交工作的，而这个只是普通渲染物件的提交，与地形，植被等工作线程也同样是并行的，这能够充分利用现代8核心乃至12核心的CPU。

对于古典的CPU管线来说，遮挡剔除比较昂贵，并且我们并不打算在此安排许多的渲染压力，因此目前只考虑视锥剔除。视锥剔除最简单粗暴的方法就是直接遍历每一个物体并计算Bounding Box，然而，这并不是一个很小的开销，我们必须有一个加速结构将这个开销降低。

我们将场景以32米为一个体素块进行切割，当Renderer发生位置移动时，通过Bounding Box判断当前Renderer所处的块，若处于多个块中，则需要让Renderer同时放到多个块中。在剔除时通过BitArray保证不会重复提交。



#### Multi Draw Indirect

还有一种方式就是使用Indirect Draw(间接绘制)，不是由CPU指定绘制目标，而是由GPU自行支配，这种时候我们就可以把模型数据长存在显存中，当使用贴图时或者顶点数据，Indirect Draw会提供索引，需要手动在shader中读取显存。

大致过程是，首先将我们需要的绘制信息放到一个结构体中

![image](https://pic2.zhimg.com/v2-f68236f248de386b8238376efb7a0d3d_r.jpg)

![](https://pic2.zhimg.com/80/v2-95a2eca8ec79e8c9953c855ccd6bdcf1_720w.jpg)

这就是我们的数据准备之后就可以创建我们的command命令， 使用CreateCommandSignature完成创建，所做的工作和GPU Instance区别并不大，但是之后的工作是创建一个负责给GPU提供指令的UploadBuffer，这样GPU就会直接从Buffer中读取这些信息，不会再经过CPU端，这样针对cpu再渲染效率上拖累GPU的问题就解决了，除此之外其他不会随着Drawcall改变而改变的数据比如摄像机位置。贴图之类的 ，仍旧按照正常的传递，传递完毕后调用ExecuteIndirect完成本次提交，注意整个pass必须保证Pipeline state统一


### Depth Prepass（later z和early z）
了解Depth Prepass需要先了解depth test，depth test就是深度测试，是为了解决图形学中遮挡关系而存在的。那么由于远处的物体后渲染，会将之前渲染的物体覆盖住，这无疑是错误的。所以要想渲染正确，就应该解决这种由渲染先后次序导致的问题。对于场景中的每个位置，记录距离相机最近的点到相机之间的距离（深度），渲染下一个物体的每个pixel之前，先比较该pixel的深度与记录下来的深度，如果比记录值大，说明要远，该pixel就不用渲染。 
对于传统的depth test（late z test）是发生在fragment shading之后的。但是仔细分析pipeline的流程后发现其实在光栅化之后fragment shading之前，fragment的深度就可以计算出来了，有了深度其实很多情况下就可以做depth test（early z test）了，这样就可以提前剔除掉被遮挡的fragment，大大节省GPU的计算能力，所以现在的pipeline如下所示（图中省去了tessellation和geometry stage）。  

depth prepass的意义，就是在一个render pass中，首先先渲染物体的深度，然后再渲染该物体的颜色。在渲染深度时，只为了更新depth buffer，所以需要打开depth test以及depth write mask，同时关闭color的write mask；depth buffer更新完成后，渲染该物体的color时，打开depth test并设置比较函数为“Equal”，打开color write mask来着色，由于depth 之前已经更新好了所以这时候应该关闭depth write mask，这样就可以完成该物体的渲染。很好的避免了复杂场景内overdraw 的问题。

later z  和 eraly z

![](https://img-blog.csdnimg.cn/20190705095825369.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2EyNTQyMTI4YQ==,size_16,color_FFFFFF,t_70)

深度测试是为了记录场景内的遮挡信息，如果前面遮挡的物体是半透明的又该如何处理，这就牵扯到alpha 测试.

### alphe测试  
https://zhuanlan.zhihu.com/p/263566318

首先确定下渲染顺序，一般情况下是先渲染不透明物体，在渲染版透明物体，渲染过程中都要开启depth，但是半透明物体是没有z write的权限的，原因很简单，他并不能遮挡他后面的物体 ，对于半透明物体的渲染，首先通过深度测试确定是否需要culling，如果没有culling，首先z buff肯定什么都不写，而需要在frame buff上，需要根据内存中的color 和 当前frame的color根据alphe进行混合。

补充：early z和alphe测试存在冲突的问题  

提前深度测试可能会与片元着色器中的透明度测试起冲突：

比如在开启了透明测试情况下，一个属于”alphatest“序列的片元已经通过了深度测试（更新了最近新的深度阈值，比它远的片元都被舍弃），但片元进行透明测试时失败，则该片元因此被舍弃，视觉上的结果就是，一个片元明明被舍弃了，却因为在Early-Z步骤中通过了深度测试，导致其背后的物体都被舍弃；此时透过这个本不存在的片元，背后却什么都看不到，但真实的情况是该片元是全透明的，应该可以看得到背后物体才对。换句话说**物体被全透明的物体挡住，这是不可能的**。

因此为了避免这种冲突，**在使用 Early-Z技术时，不可以使用AlphaTest技术。在Unity的实际应用中**，当使用了**AlphaTest，为了避免冲突，Early-Z技术就会失效。**（这也是使用AlphaTest时，场景中因overdraw过多时影响开销的因素）





## 数学
### 坐标系
#### 2D坐标系
- 2D 笛卡尔坐标系。主要运用有序数对来表示点的位置信息
- 2D 极坐标：方向和距离来定义点
- 笛卡尔和极坐标之间的转换。

```
  极坐标 to 笛卡尔
  
  x = rcos(θ)
  y = rsin(θ)
  
  笛卡尔 to 极坐标
  r = sqrt(x^2+y^2)
  θ = arctan(y/x)=tan^-1(y/x)  —— tan的反三角函数
  
  warming:当x=0时，正切为无穷大！！！若x=0，则θ=90

```
#### 3D坐标系
- 3D笛卡尔坐标系  
三条轴（有三个相互正交的向量组成）、八个卦限、三个平面（两两组成）
依据新增的Z轴方向的不同，分为左手坐标系（LHS）和右手坐标系（RHS）
- 3D柱面坐标（三维的极坐标）  
只是在二维极坐标上加了一个描述高度的变量（Z轴）
点的表示：(r,θ,h)
- 三维笛卡尔和柱面坐标的相互转换

```
  极坐标 to 笛卡尔
  
  x = rcos(θ)
  y = rsin(θ)
  z = z;
  
  笛卡尔 to 极坐标
  
  r = sqrt(x^2+y^2)
  θ = arctan(y/x)=tan^-1(y/x)  —— tan的反三角函数
  z = z;
  
  warming：x=0时与二维转换的类似，不再复述

```

### 向量的点乘、叉乘
#### 点乘：  
向量的点乘：a · b = |a| * |b| * cosθ  
数学定义：a · b =x1 · x2 + y1 · y2
点乘的几何意义:  
- 计算两个向量之间的夹角,判断这两个向量是否垂直。
- 计算一个向量在另一个向量方向上的投影长度。

#### 叉乘
向量的叉乘：a ∧ b = |a| * |b| * sinθ
数学定义: a X b = x1 · y1 - y2 · x2   
点乘的几何意义:  
- 在三维几何中，向量a和向量b的叉乘结果是一个向量，更为熟知的叫法是法向量，该向量垂直于a和b向量构成的平面。
- 在二维几何中，叉乘还有另外一个几何意义就是：aXb等于由向量a和向量b构成的平行四边形的面积。